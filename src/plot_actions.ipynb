{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(reward, portion_same)\n",
      "[(0.0, 0.5719784449576597), (0.003676470588235294, 0.6104651162790697), (0.007352941176470588, 0.07792207792207792), (0.011029411764705883, 0.14814814814814814), (0.022058823529411766, 0.3146853146853147), (0.025735294117647058, 0.7777777777777778), (0.029411764705882353, 0.24), (0.05514705882352941, 0.0), (0.058823529411764705, 1.0), (0.29411764705882354, 1.0), (0.3235294117647059, 1.0), (0.34558823529411764, 1.0), (0.35294117647058826, 1.0), (0.35661764705882354, 1.0), (0.3602941176470588, 1.0), (0.3639705882352941, 0.6666666666666666), (0.375, 1.0), (0.38235294117647056, 0.5), (0.7058823529411765, 1.0), (0.7242647058823529, 1.0), (0.7352941176470589, 0.9534883720930233), (0.7647058823529411, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\"\"\"\n",
    "author(s): Arnold Unterauer\n",
    "\"\"\"\n",
    "\n",
    "####################\n",
    "\n",
    "env_name = \"3s_vs_3z\"\n",
    "compare_token_0 = \"qtran__2022-07-17_19-20-46_276\"\n",
    "# compare_token_1 = \"qtran__2022-07-16_11-35-04_83\"\n",
    "\n",
    "####################\n",
    "\n",
    "def extract_data(env_name, unique_token):\n",
    "    save_eval_buffer_path = os.path.join(os.getcwd(), \"results\", \"models\", \"custom\", env_name, unique_token)\n",
    "    with open(os.path.join(save_eval_buffer_path, \"unique_eval_buffer.txt\"), \"r\") as f:\n",
    "        eval_buffer = json.load(f)\n",
    "\n",
    "    with open(os.path.join(save_eval_buffer_path, \"args.txt\"), \"r\") as f:\n",
    "        args = json.load(f)\n",
    "    args = SimpleNamespace(**args)\n",
    "\n",
    "    rewards_mac = eval_buffer[0][0]\n",
    "    actions_mac = eval_buffer[0][1]\n",
    "    if args.train_hidden_a_learner or args.train_simultaneously or args.pure_antagonist or args.only_gan:\n",
    "        rewards_hidden_mac = eval_buffer[1][0]\n",
    "        actions_hidden_mac = eval_buffer[1][1]\n",
    "        return True, args.n_antagonists, rewards_mac, actions_mac, rewards_hidden_mac, actions_hidden_mac\n",
    "    return False, 0, rewards_mac, actions_mac, None, None\n",
    "\n",
    "def get_bined_actions(rewards, actions):\n",
    "    unique_rewards = [sum(reward) / len(reward) for reward in rewards]\n",
    "    rewards_set = list(set(unique_rewards))\n",
    "    sorted_rewards_set = sorted((e,i) for i,e in enumerate(rewards_set))\n",
    "\n",
    "    index_reward_dict = {}\n",
    "    for e in sorted_rewards_set:\n",
    "        index_reward_dict['{}'.format(e[0])] = e[1]\n",
    "\n",
    "    bined_rewards_indices = [[] for _ in range(len(rewards_set))]\n",
    "    for i, r in enumerate(unique_rewards):\n",
    "        bined_rewards_indices[index_reward_dict['{}'.format(r)]].append(i)\n",
    "    bined_actions = [[actions[r] for r in bined_rewards] for bined_rewards in bined_rewards_indices]\n",
    "\n",
    "    return bined_actions\n",
    "\n",
    "####################\n",
    "\n",
    "hidden_exist_0, n_antagonists, \\\n",
    "rewards_mac_0, actions_mac_0, \\\n",
    "rewards_hidden_mac_0, actions_hidden_mac_0 \\\n",
    "    = extract_data(env_name, compare_token_0)\n",
    "\n",
    "bined_actions_mac = get_bined_actions(rewards_mac_0, actions_mac_0)\n",
    "if hidden_exist_0:\n",
    "    bined_actions_hidden_mac = get_bined_actions(rewards_hidden_mac_0, actions_hidden_mac_0)\n",
    "\n",
    "actions = []\n",
    "for bined_action_mac in bined_actions_mac:\n",
    "    bin_actions = []\n",
    "    for action in bined_action_mac:\n",
    "        for a in action[- n_antagonists:]:\n",
    "            bin_actions.append(a)\n",
    "    actions.append(bin_actions)\n",
    "\n",
    "hidden_actions = []\n",
    "for bined_action_hiiden_mac in bined_actions_hidden_mac:\n",
    "    bin_actions = []\n",
    "    for action in bined_action_hiiden_mac:\n",
    "        for a in action[- n_antagonists:]:\n",
    "            bin_actions.append(a)\n",
    "    hidden_actions.append(bin_actions)\n",
    "\n",
    "same_actions = []\n",
    "for i, action in enumerate(actions):\n",
    "    same_action = []\n",
    "    for j in range(len(action)):\n",
    "        if actions[i][j] == hidden_actions[i][j]:\n",
    "            same_action.append(True)\n",
    "        else:\n",
    "            same_action.append(False)\n",
    "    same_actions.append(same_action)\n",
    "\n",
    "unique_rewards = [sum(reward) / len(reward) for reward in rewards_mac_0]\n",
    "rewards_set = list(set(unique_rewards))\n",
    "sorted_rewards_set = sorted((e,i) for i,e in enumerate(rewards_set))\n",
    "\n",
    "same_portion = []\n",
    "for a_i in range(len(same_actions)):\n",
    "    same_portion.append((sorted_rewards_set[a_i][0], sum(same_actions[a_i]) / len(same_actions[a_i])))\n",
    "\n",
    "print(\"(reward, portion_same)\")\n",
    "print(same_portion)\n",
    "\n",
    "# TODO rewards are wrong"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}